# -*- mode: Snakemake -*-
# Post-Alignment Processing: BLAT

# Map reads to genome and create list of unique sites for each sample
rule post_align:
  input:
    sampleR1=PROC_DIR + "/analysis_data/{sample}.R1.psl.gz",
    sampleR2=PROC_DIR + "/analysis_data/{sample}.R2.psl.gz",
    keyR1=PROC_DIR + "/analysis_data/{sample}.R1.key.csv",
    keyR2=PROC_DIR + "/analysis_data/{sample}.R2.key.csv"
  output:
    uniq=PROC_DIR + "/analysis_data/uniqSites/{sample}.uniq.csv",
    chimera=PROC_DIR + "/analysis_data/chimeras/{sample}.chimera.rds",
    multihit=PROC_DIR + "/analysis_data/multihits/{sample}.multihits.rds"
  params:
    tool=CODE_DIR + "/couple.R",
    ref=config["Ref_Genome"]
  log:
    PROC_DIR + "/logs/{sample}.couple.log"
  resources:
    mem_mb=lambda wildcards, attempt: attempt * config["coupleMB"]
  shell:
    """
    Rscript {params.tool} {input.sampleR2} {input.sampleR1} \
      -k {input.keyR2} {input.keyR1} \
      -o {output.uniq} --chimera {output.chimera} --multihit {output.multihit} \
      -g {params.ref} > {log} 2>&1
    """

# Create list of all unique sites
rule all_uniq_sites:
  input:
    expand(PROC_DIR + "/analysis_data/uniqSites/{sample}.uniq.csv", sample=SAMPLES)
  output:
    PROC_DIR + "/output_data/unique_sites." + RUN + ".csv"
  shell:
    """
    OUT_DIR="{PROC_DIR}/analysis_data"
    head -n 1 -q ${{OUT_DIR}}/uniqSites/* | uniq > {output}
    cat ${{OUT_DIR}}/uniqSites/* | sed '/seqnames/d' >> {output}
    """

def report_supp(wildcards):
  supp_str = str()
  if (config["figures"]): 
      supp_str = supp_str + "-f "
  if (config["reportData"]):
      supp_str = supp_str + "-d "
  if (config["suppFile"]):
      supp_str = supp_str + "-s " + config["Supplemental_Info"]
  supp_str = supp_str + " -t " + config["reportFormat"]
  return supp_str

# Standardize and condense int sites, filter for crossovers between samples, and create summary table
rule initial_assessment:
  input:
    data=PROC_DIR + "/output_data/unique_sites." + RUN + ".csv",
    supp=config["Supplemental_Info"]
  output:
    stdSites=PROC_DIR + "/output_data/standardized_uniq_sites." + RUN + ".rds",
    condSites=PROC_DIR + "/output_data/condensed_sites." + RUN + ".csv",
    xofilSites=PROC_DIR + "/output_data/xofil_condensed_sites." + RUN + ".csv",
    readMat=PROC_DIR + "/output_data/read_site_matrix." + RUN + ".csv",
    fragMat=PROC_DIR + "/output_data/fragment_site_matrix." + RUN + ".csv",
    sumTbl=PROC_DIR + "/output_data/summary_table." + RUN + ".csv"
  params:
    tool=CODE_DIR + "/initial_assessment.R",
    proc=PROC_DIR + "/output_data",
    inst=ROOT_DIR,
    run = RUN
  log:
    PROC_DIR + "/logs/" + RUN + ".init.assessment.log"
  resources:
    mem_mb=lambda wildcards, attempt: attempt * config["processMB"]
  shell:
    "Rscript {params.tool} {input.data} {params.proc} {params.run} {params.inst} {input.supp} > {log} 2>&1"
  
# Generate report for chiva run
rule run_report:
  input:
    data=PROC_DIR + "/output_data/standardized_uniq_sites." + RUN + ".rds",
    supp=config["Supplemental_Info"]
  output: PROC_DIR + "/output_data/report." + RUN + "." + config["reportFormat"]
  params: 
    tool = CODE_DIR + "/generate_HIV_report.R",
    config = PROC_DIR + "/" + RUN + ".config.yml"
  log: 
    PROC_DIR + "/logs/" + RUN + ".report.log"
  resources:
    mem_mb=lambda wildcards, attempt: attempt * config["reportMB"]
  shell:
    """
    Rscript {params.tool} {input.data} -o {output} \
      -c {params.config} -s {input.supp} > {log} 2>&1
    """
